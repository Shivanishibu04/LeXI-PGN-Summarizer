# LeXI-Phase-2: Hybrid Legal Document Summarization

A hybrid extractive-abstractive summarization system for legal documents using Pointer-Generator Networks.

## ğŸ¯ Overview

This project implements a complete pipeline for legal text summarization combining:
- **Extractive Component**: CNN-CRF sentence boundary detection + SentenceSummarizer
- **Abstractive Component**: Pointer-Generator Network with attention and coverage mechanism

## ğŸ—ï¸ Architecture

```
Legal Document
    â†“
[CNN-CRF] Sentence Segmentation
    â†“
[SentenceSummarizer] Extract Top-K Sentences
    â†“
[SentencePiece BPE] Tokenization
    â†“
[Pointer-Generator Network]
  â€¢ BiLSTM Encoder
  â€¢ LSTM Decoder  
  â€¢ Bahdanau Attention
  â€¢ Copy Mechanism
  â€¢ Coverage Loss
    â†“
Abstractive Summary
```

## ğŸ“Š Features

- âœ… Hybrid extractive-abstractive approach
- âœ… CNN-CRF for accurate legal sentence boundary detection
- âœ… Pointer-Generator with copy mechanism for handling legal terminology
- âœ… Coverage mechanism to reduce repetition
- âœ… Comprehensive evaluation metrics (ROUGE, BLEU, METEOR, BERTScore)
- âœ… Fast training mode for CPU (1-2 hours)
- âœ… Research-grade code suitable for publication

## ğŸš€ Quick Start

### Installation

```bash
pip install -r requirements_pgn.txt
pip install -r requirements_evaluation.txt
```

### Fast Training (1-2 hours on CPU)

```bash
python train_fast.py
```

### Generate Summaries

```bash
python inference.py \
    --checkpoint pgn_output_fast/models/checkpoint_epoch10_step660.pt \
    --input summariser_dataset/test.csv \
    --output results.csv
```

### Evaluate

```bash
python evaluate.py \
    --checkpoint pgn_output_fast/models/checkpoint_epoch10_step660.pt \
    --input summariser_dataset/test.csv
```

## ğŸ“ Project Structure

```
LeXI-Phase-2/
â”œâ”€â”€ models/                    # Neural network components
â”‚   â”œâ”€â”€ encoder.py            # BiLSTM encoder
â”‚   â”œâ”€â”€ decoder.py            # LSTM decoder with attention
â”‚   â”œâ”€â”€ attention.py          # Bahdanau attention
â”‚   â””â”€â”€ pointer_generator.py # Complete PGN model
â”‚
â”œâ”€â”€ data_utils/               # Data processing
â”‚   â”œâ”€â”€ preprocessing.py      # Extractive filtering & tokenization
â”‚   â””â”€â”€ dataset.py           # PyTorch dataset
â”‚
â”œâ”€â”€ src/                      # Existing models
â”‚   â”œâ”€â”€ cnn_model.py         # CNN for sentence boundaries
â”‚   â”œâ”€â”€ crf_model.py         # CRF model
â”‚   â””â”€â”€ summarizer.py        # Extractive summarizer
â”‚
â”œâ”€â”€ train.py                  # Full training script
â”œâ”€â”€ train_fast.py            # Fast training (CPU optimized)
â”œâ”€â”€ inference.py             # Generate summaries
â”œâ”€â”€ evaluate.py              # Comprehensive evaluation
â”œâ”€â”€ config.py                # Full configuration
â””â”€â”€ config_fast.py           # Fast configuration
```

## ğŸ“Š Evaluation Metrics

The system evaluates generated summaries using:

- **ROUGE** (1, 2, L): Overlap-based metrics
- **BLEU**: Precision-based n-gram metric
- **METEOR**: Semantic similarity with synonyms
- **BERTScore**: Contextual embedding similarity
- **Abstractiveness**: Novel content generation
- **Length metrics**: Compression ratio, length ratio

## ğŸ¯ Expected Performance

Fast training mode (1-2 hours, 15% data):
- ROUGE-1: 0.30-0.40
- ROUGE-2: 0.12-0.20
- Abstractiveness: 0.40-0.60

Full training mode (60-100 hours, 100% data):
- ROUGE-1: 0.40-0.48
- ROUGE-2: 0.18-0.26
- Production-quality summaries

## ğŸ“š Documentation

- [`PGN_README.md`](PGN_README.md) - Detailed architecture and usage
- [`QUICK_START.md`](QUICK_START.md) - Quick start guide with commands
- [`TRAINING_TIME_GUIDE.md`](TRAINING_TIME_GUIDE.md) - Time estimates and optimization
- [`EVALUATION_METRICS.md`](EVALUATION_METRICS.md) - Metrics explanation
- [`INTEGRATION_CONFIRMED.md`](INTEGRATION_CONFIRMED.md) - Component integration details
- [`TOMORROW_CHECKLIST.md`](TOMORROW_CHECKLIST.md) - Step-by-step workflow

## ğŸ› ï¸ Requirements

- Python 3.7+
- PyTorch 1.9+
- SentencePiece
- sklearn-crfsuite
- NLTK
- See `requirements_pgn.txt` and `requirements_evaluation.txt` for full list

## ğŸ† Research Context

This implementation is based on:

```bibtex
@article{see2017get,
  title={Get To The Point: Summarization with Pointer-Generator Networks},
  author={See, Abigail and Liu, Peter J and Manning, Christopher D},
  journal={arXiv preprint arXiv:1704.04368},
  year={2017}
}
```

Extended for legal domain with hybrid extractive-abstractive approach.

## ğŸ“ Citation

If you use this code in your research, please cite:

```bibtex
@misc{lexi-phase2,
  title={LeXI Phase 2: Hybrid Legal Document Summarization},
  author={[Your Name]},
  year={2025},
  howpublished={\url{https://github.com/[your-username]/LeXI-Phase-2}}
}
```

## ğŸ“„ License

[Your chosen license - e.g., MIT, Apache 2.0]

## ğŸ™ Acknowledgments

- Existing CNN-CRF sentence boundary detection system
- SentenceSummarizer extractive component
- Pointer-Generator Networks (See et al., 2017)

## ğŸ“§ Contact

[Your contact information or leave blank]

---

**Note**: Dataset files are not included in this repository due to size. The system expects CSV files in `summariser_dataset/` with columns: `Text` (full document) and `Summary` (gold summary).
